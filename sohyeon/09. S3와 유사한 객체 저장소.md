# 9장 S3와 유사한 객체 저장소

## 저장소 시스템 101

### 블록 저장소
- 원시 블록(raw block)을 서버에 볼륨(volume) 형태로 제공한다.
- 가장 유용하고 융통성이 높은 저장소다.
- 서버에 물리적으로 직접 연결되는 저장소에 국한되지 않는다.

<br/>

### 파일 저장소
- 블록 저장소 위에 구현된다. (더 높은 추상화 제공)
- 가장 널리 사용되는 범용 저장소 솔루션이다.
- 파일 저장소를 사용하는 서버는 블록을 직접 제어하고, 볼륨을 포맷하는 등의 까다로운 작업을 신경 쓸 필요없다.
- 단순하기 때문에 폴더나 파일을 같은 조직 구성원에 공유하는 솔루션으로 사용하기 좋다.

<br/>

### 객체 저장소
- 데이터 영속성을 높이고 대규모 애플리케이션을 지원하며, 비용을 낮추기 위해 의도적으로 성능을 희생한다.
- 상대적으로 차가운(cool) 데이터 보관에 초점을 맞추며 데이터 아카이브나 백업에 주로 쓰인다.
- 모든 데이터를 수평적 구조 내에 객체로 보관한다.
- 데이터 접근은 보통 RESTful API를 통한다. (상대적으로 느림)
- ex. AWS S3, Azure Blob Storage

<br/>

## 1️⃣ 문제 이해 및 설계 범위 확정

### 기능 요구사항
- 버킷 생성
- 객체 업로드 및 다운로드
- 객체 버전
- 버킷 내 객체 목록 출력 기능

<br/>

### 비기능 요구사항
- 100PB 데이터
- 식스 나인 수준의 데이터 내구성
- 포 나인 수준의 서비스 가용성
- 저장소 효율성: 높은 수준의 안정성과 성능은 보증하되 저장소 비용은 최대한 낮추어야 함

<br/>

### 대략적인 규모 추정
- 디스크 용량
  - 20%: 1MB 미만
  - 60%: 1MB ~ 64MB
  - 20%: 64MB 이상
 
- IOPS: 하드 디스크 하나가 초당 100~150회의 임의 데이터 탐색을 지원할 수 있다고 가정
- 저장소에 수용 가능한 객체 수: 100PB (0.68TB 정도의 공간 필요)

<br/>

## 2️⃣ 개략적 설계안 제시 및 동의 구하기
- 객체 불변성
- 키-값 저장소
- 저장은 1회, 읽기는 여러 번
- 소형 및 대형 객체 동시 지원

<br/>

### 개략적 설계안

<img alt="image" width="500" src="https://github.com/user-attachments/assets/16f45d21-5783-4713-8a87-6d38d9df879c"/>

- 로드밸런서: 요청을 서버들에 분산
- API 서비스: 인증, 권한 부여, 접근 제어 등을 중앙에서 맡아 처리
- 데이터 저장소: 실제 데이터를 보관하고 필요할 때마다 읽어가는 장소
- 메타데이터 저장소: 객체 메타데이터 보관 장소

<br/>

### 객체 업로드

<img alt="image" width="500" src="https://github.com/user-attachments/assets/35d59c1d-46d7-4557-ba66-3ced5fc9d65a"/>

- 객체는 버킷 안에 두어야 한다.
- 예제에서는 bucket-to-share라는 버킷 생성 후 파일 script.txt 파일을 업로드한다.
- 과정은 크게 7단계로 나누어진다.

<br/>

### 객체 다운로드

<img alt="image" width="500" src="https://github.com/user-attachments/assets/3d0dd078-3c07-4e08-aecd-88611e769e00"/>

- 버킷은 디렉터리 같은 계층 구조를 지원하지 않는다.
- 버킷 이름과 객체 이름을 연결하여 논리적 계층을 만들 수 있다. (ex. bucket-to-share/script.txt)

<br/>

## 3️⃣ 상세 설계

### 데이터 저장소
- API 서비스는 사용자의 요청을 받으면 그 요청을 처리하기 위해 다른 내부 서비스들을 호출한다.
- 객체를 저장하거나 가져오는 작업은 데이터 저장소를 호출하여 처리한다.

<br/>

### 데이터 저장소의 개략적 설계

<img alt="image" width="500" src="https://github.com/user-attachments/assets/52a18413-b5ea-4806-b10d-0fa8311086cb"/>

<br/>

### 데이터 라우팅 서비스
- 배치 서비스를 호출하여 데이터를 저장할 최적의 데이터 노드를 판단
- 데이터 노드에서 데이터를 읽어 API 서비스에 반환
- 데이터 노드에 데이터 기록

<br/>

### 배치 서비스
- 어느 데이터 노드에 데이터를 저장할지 결정한다.
- 보관되는 데이터 노드의 위치 정보를 이용하여 데이터 사본(replica)이 물리적으로 다른 위치에 놓이도록 한다.
- 물리적인 분리는 높은 데이터 내구성을 달성하는 핵심 요소다.

<br/>

### 데이터 노드
- 실제 객체 데이터가 보관된다.
- 각 데이터 노드는 배치 서비스에 주기적으로 박동 메시지를 보낸다.
  - 해당 데이터 노드에 부착된 HDD/SSD 수
  - 각 드라이브에 저장된 데이터의 양
 
- 처음 박동 메시지를 보내면 ID를 부여받고, 데이터를 반환받는다.
  - 해당 데이터 노드에 부여한 고유 식별자
  - 가상 클러스터 지도
  - 데이터 사본을 보관할 위치
 
<br/>

### 데이터 저장 흐름

<img alt="image" width="500" src="https://github.com/user-attachments/assets/e6f39192-50b5-4e90-876a-1e7c81b42422"/>

- 데이터가 어떻게 데이터 노드에 영속적으로 보관되는지 나타낸다.

<br/>

### 데이터는 어떻게 저장되는가
- 각각의 객체를 개별 파일로 저장한다. (가장 단순함)
  - 👎 낭비되는 데이터 블록 수가 늘어난다.
  - 👎 시스템의 아이노드(inode) 용량 한계를 초과한다.
 
- 작은 객체들을 큰 파일 하나로 모아서 해결한다. (객체를 저장할 때 이미 존재하는 파일에 추가하는 방식)

<br/>

### 객체 소재 확인
- UUID로 객체 위치를 찾기 위해 다음 정보가 필요하다.
  - 객체가 보관된 데이터 파일
  - 데이터 파일 내 객체 오프셋(offset)
  - 객체 크기
 
- 읽기 연산 성능이 좋은 관계형 데이터베이스를 선택하는 것이 좋다. (for 정보 저장)

<br/>

### 개선된 데이터 저장 흐름
1. API 서비스는 새로운 객체를 저장하는 요청을 데이터 노드 서비스에 전송한다.
2. 데이터 노드 서비스는 객체를 읽기-쓰기 파일 /data/c의 마지막 부분에 추가한다.
3. 해당 객체에 대한 새로운 레코드를 object_mapping 테이블에 추가한다.
4. 데이터 노드 서비스는 API 서비스에 해당 객체의 UUID를 반환한다.

<br/>

### 데이터 내구성

#### 하드웨어 장애와 장애 도메인
- 데이터를 여러 대의 하드 드라이브에 복제하여 어떤 드라이브에서 발생한 장애가 전체 데이터 가용성에 영향을 주지 않도록 한다.
- 데이터를 여러 AZ에 복제해 놓으면 장애 여파를 최소화할 수 있다. (가용성 구역)

<br/>

#### 소거 코드
- 데이터를 작은 단위로 분할하여 다른 서버에 배치하는 한편, 그 가운데 일부가 소실되었을 때 복구하기 위한 패리티(parity)라는 정보를 만들어 중복성을 확보한다.
- 장애가 생기면 남은 데이터와 패리티를 조합하여 소실된 부분을 복구한다.
- 최대 4대 노드에 장애가 동시에 발생하더라도 원본 데이터를 복원할 수 있다.
- 응답 지연은 높아지는 대신 내구성은 향상되고 저장소 비용은 낮아진다. (최대 8개의 건강한 노드에서 데이터를 가져와야 함)

<br/>

### 정확성 검증
- 원본 데이터의 체크섬을 알면 전송 받은 데이터의 정확성은 해당 데이터의 체크섬을 다시 계산한 후 다음과 같은 절차로 확인 가능하다.
  - 새로 계산한 체크섬이 원본 체크섬과 다르면 데이터가 망가진 것이다.
  - 같은 경우에는 아주 높은 확률로 데이터는 온전하다고 볼 수 있다.
  - 체크섬 알고리즘은 MD5, SHA1, HMAC 등 다양하다.
 
<br/>

### 메타데이터 데이터 모델
#### 스키마
- bucket
  - bucket_name
  - bucket_id
  - owner_id
  - enable_versioning
 
- object
  - bucket_name
  - object_name
  - object_version
  - object_id
 
<br/>

#### bucket 테이블의 규모 확장
- 모든 읽기 요청을 처리하기에는 CPU 용량이나 네트워크 대역폭이 부족할 수 있다.
- 데이터베이스 사본을 만들어 읽기 부하를 분산할 수 있다.

<br/>

#### object 테이블의 규모 확장
- 샤딩을 통해 객체 메타데이터 테이블의 규모를 확장한다.
  - bucket_id 기준: 핫스팟 샤드 지원 불가
  - object_id 기준: 부하를 균등하게 분산하지만, 일부 질의(URI 기준)의 효율적 지원 불가
  - **bucket_name & object_name** 기준: 대부분의 메타데이터 관련 연산이 객체 URI을 기준으로 함
 
<br/>

### 버킷 내 객체 목록 확인
1. 어떤 사용자가 가진 모든 버킷 목록 출력
2. 주어진 접두어를 가진, 같은 버킷 내 모든 객체 목록 출력
3. 주어진 접두어를 가진, 같은 버킷 내 모든 객체를 재귀적으로 출력

<br/>

### 단일 데이터베이스 서버
- 공통 접두어로 갖는 모든 객체를 찾는다.
- 해당 접두어 이후에 더 많은 슬래시 기호가 포함된 이름을 가진 객체들을 디렉터리처럼 보이도록 묶는 작업은 애플리케이션이 담당한다.

<br/>

### 분산 데이터베이스
1. 메타데이터 서비스는 모든 샤드에 질의를 돌린다.
2. 메타데이터 서비스는 각 샤드가 반환한 객체들을 취합하여 그 결과를 호출하고 클라이언트에 반환한다.
   - 서버는 모든 샤드의 오프셋을 추적하여 커서에 결부시킬 수 있어야 함
  
<br/>

### 객체 버전
- 버킷 안에 한 객체의 여러 버전을 둘 수 있도록 하는 기능이다.
- 객체 저장소는 해당 문서의 모든 이전 버전을 메타데이터 저장소에 유지하고, 이전 버전에 삭제 표시를 한다거나 하지 않는다.

<br/>

### 큰 파일의 업로드 성능 최적화
- 큰 객체는 작게 쪼갠 다음 독립적으로 업로드하는 것이 좋다.
  - 모든 조각이 업로드된 후 객체 저장소는 그 조각을 모아서 원본 객체를 복원한다. (멀티파트 업로드)
 
- 객체 조립 후에 조각들은 더 이상 쓸모가 없다. 조각을 삭제하여 저장 용량을 확보할 필요가 있다. (쓰레기 수집 프로세스 구현)

<br/>

### 쓰레기 수집(GC)
- 더 이상 사용되지 않는 데이터에 할당된 저장 공간을 자동으로 회수한다.
  - 객체의 지연된 삭제
  - 갈 곳 없는 데이터
  - 훼손된 데이터
 
- 삭제된 객체는 정리 메커니즘을 주기적으로 실행하여 지운다.
- 사용되지 않는 사본에 할당된 저장 공간을 회수한다.

<br/>

## 4️⃣ 마무리
- 객체 저장소의 개략적 설계안
- 블록 저장소, 파일 저장소, 객체 저장소 비교
- 관련 기능 구현 방식
- 다중화와 소거 코드
- 멀티파트 업로드 실행 과정
- 쓰레기 수집 방법
