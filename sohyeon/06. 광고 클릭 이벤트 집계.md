# 6장 광고 클릭 이벤트 집계

<img alt="image" width="700" src="https://github.com/user-attachments/assets/f3a38371-73ef-4551-adf4-2d2c2e187437"/>

🔼 RTB 동작 절차

<br/>

## 1️⃣ 문제 이해 및 설계 범위 확정

### 기능 요구사항
- 지난 M분 동안의 ad_id 클릭 수 집계
- 매분 가장 많이 클릭된 상위 100개 광고 아이디를 반환
- 다양한 속성에 따른 집계 필터링을 지원
- 데이터의 양은 페이스북이나 구글 규모

<br/>

### 비기능 요구사항
- 집계 결과 정확성은 데이터가 RTB 및 광고 과금에 사용되므로 중요
- 지연되거나 중복된 이벤트를 적절히 처리할 수 있어야 함
- 견고성: 부분적인 장애는 감내할 수 있어야 함
- 지연 시간 요구사항: 전체 처리 시간은 최대 수 분을 넘지 않아야 함

<br/>

### 개략적 추정
- DAU 10억명
- 하루에 10억 건의 광고 클릭 이벤트가 발생
- 광고 클릭 QPS = 10,000 (10^9 / 10^5)
- 최대 광고 클릭 QPS는 평균 QPS의 5배로 가정
- 월간 저장 용량 요구량은 대략 3TB

<br/>

## 2️⃣ 개략적 설계안 제시 및 동의 구하기

### 질의 API 설계

#### 지난 M분간 각 ad_id에 발생한 클릭 수 집계

```
GET /v1/ads/{:ad_id}/aggregated_count
```
- 주어진 ad_id에 발생한 이벤트 수를 집계하여 반환

<br/>

> **Request**

|인자명|뜻|자료형|
|--|--|--|
|from|집계 시작 시간|long|
|to|집계 종료 시간|long|
|filter|필터링 전략 식별자|long|

<br/>

> **Response**

|필드명|뜻|자료형|
|--|--|--|
|ad_id|광고(ad) 식별자|string|
|count|집계된 클릭 횟수|long|

<br/>

#### 지난 M분간 가장 많은 클릭이 발생한 상위 N개 ad_id 목록

```
GET /v1/ads/popular_ads
```
- 지난 M분간 가장 많은 클릭이 발생한 상위 N개 광고 목록 반환

<br/>

> **Request**

|인자명|뜻|자료형|
|--|--|--|
|count|상위 몇 개의 광고를 반환할 것인가|integer|
|window|분 단위로 표현된 집계 윈도 크기|integer|
|filter|필터링 전략 식별자|long|

<br/>

> **Response**

|필드명|뜻|자료형|
|--|--|--|
|ad_ids|광고 식별자 목록|array|

<br/>

### 데이터 모델

#### 집계 결과 데이터

|ad_id|click_minute|filter_id|count|
|--|--|--|--|
|...|...|...|...|

🔼 필터를 사용해 집계한 데이터

<br/>

#### 비교

| |원시 데이터만 보관하는 방안|집계 결과 데이터만 보관하는 방안|
|--|--|--|
|장점|- 원본 데이터를 손실 없이 보관 <br/> - 데이터 필터링 및 재계산 지원|- 데이터 용량 절감 <br/> - 빠른 질의 성능|
|단점|- 막대한 데이터 용량<br/> - 낮은 질의 성능|- 데이터 손실|

- 결론: 둘 다 저장하는 것이 좋다.
  - 문제가 발생하면 원시 데이터로 디버깅 가능하다.
  - 집계 결과 데이터로 빠르게 질의할 수 있다.

<br/>

### 올바른 데이터베이스의 선택
- (원시 데이터) 쓰기 및 시간 범위 질의에 최적화된 카산드라나 InfluxDB를 사용하는 것이 좀 더 바람직하다.
- (집계 데이터) 원시 데이터와 같은 유형의 데이터베이스를 활용하는 것이 가능하다.

<br/>

### 개략적 설계안

#### 비동기 처리
- 카프카 같은 메시지 큐를 도입하여 생산자와 소비자의 결합을 끊으면, 그 결과로 전체 프로세스는 비동기 방식으로 동작하게 되고, 생산자와 소비자의 규모를 독립적으로 확장해 나갈 수 있게 된다.

<br/>

<img alt="image" width="500" src="https://github.com/user-attachments/assets/479907ad-1654-43db-9fc7-b9e859d1e43d"/>

🔼 개략적 설계안

<br/>

<img alt="image" width="500" src="https://github.com/user-attachments/assets/171748bd-c5d9-410e-9790-153705a0585a"/>

🔼 정확하게 한 번 처리하기 위한 메커니즘

<br/>

### 집계 서비스
- 맵 노드: 데이터 출처에서 읽은 데이터를 필터링하고 변환하는 역할

<br/>

### 집계 노드
- 리듀스 노드: 모든 `집계` 노드가 산출한 결과를 최종 결과로 축약
- 주요 사용 사례
  - 클릭 이벤트 수 집계
  - 가장 많이 클릭된 상위 N개 광고 반환
  - 데이터 필터링
 
<br/>

## 3️⃣ 상세 설계

### 스트리밍 vs 일괄 처리
- 일괄 및 스트리밍 처리 경로를 동시에 지원하는 시스템의 아키텍처를 람다라고 부른다.

<br/>

| |서비스(온라인 시스템)|일괄 처리 시스템(오프라인 시스템)|스트리밍 시스템(실시간에 가깝게 처리하는 시스템)|
|--|--|--|--|
|응답성|클라이언트에게 빠르게 응답|클라이언트에게 응답할 필요가 없음|클라이언트에게 응답할 필요가 없음|
|입력|사용자의 요청|유연한 크기를 갖는 입력|입력에 경계가 없음|
|출력|클라이언트에 대한 응답|구체화 뷰, 집계 결과 지표 등|구체화 뷰, 집계 결과 지표 등|
|성능 측정 기준|가용성, 지연 시간|처리량|처리량, 지연 시간|
|사례|온라인 쇼핑|맵리듀스|플링크|

<br/>

#### 데이터 재계산
- 이미 집계한 데이터를 다시 계산해야 하는 경우가 있는데, 이를 이력 데이터 재처리라고 한다.
- 재계산 프로세스는 데이터 집계 서비스를 재사용하기는 하지만 처리 대상 데이터는 다른 곳에서 읽는다.

<br/>

### 시간
- 이벤트 시각: 광고 클릭이 발생한 시각
  - 👍 집계 결과가 보다 정확하다.
  - 👎 타임스탬프에 의존하므로 설정 시각 오류 또는 의도적인 조작 문제에서 자유로울 수 없다.
- 처리 시각: 집계 서버가 클릭 이벤트를 처리한 시스템 시각
  - 👍 서버 타임스탬프가 보다 안정적이다.
  - 👎 집계 결과가 보다 부정확할 수 있다.
 
<br/>

### 집계 윈도
- 텀블링 윈도는 시간을 같은 크기의 겹치지 않는 구간으로 분할한다. (매 분 발생한 클릭 이벤트 집계에 적합함)
- 슬라이딩 윈도는 데이터 스트림을 미끄러져 나아가면서 같은 구간 안에 있는 이벤트를 집계한다. (M분간 가장 많이 클릭된 상위 N개 광고를 알아내기에 적합함)

<br/>

### 전달 보장
- 이벤트의 중복 처리를 어떻게 피할 수 있는가?
- 모든 이벤트의 처리를 어떻게 보장할 수 있는가?
- 본 설계안에서는 `정확히 한 번` 방식을 권장한다.
  - 데이터 손실을 막으려면 다운스트림에서 집계 결과 수신 확인 응답을 받은 후 오프셋을 저장해야 한다.
 
<br/>

### 시스템 규모 확장
- 메시지 큐의 규모 확장
  - 생산자: 쉬움 (인스턴스 수 제한 X)
  - 소비자: 노드 추가/삭제를 통해 쉽게 조정 가능 (트래픽 적은 시간대에)
 
- 브로커
  - 해시 키: 같은 id를 갖는 이벤트를 전부 같은 파티션에서 구독 가능
  - 파티션의 수: 사전에 충분한 수만큼 확보 필요
  - 토픽의 물리적 샤딩: 여러 토픽을 두면 처리 대역폭을 높일 수 있지만, 유지 관리 비용도 커짐
 
- 집계 서비스의 규모 확장
  - 노드의 추가/삭제를 통해 수평적으로 조정이 가능하다.
 
- 데이터베이스의 규모 확장
  - 안정 해시와 유사한 방식으로 수평적인 규모 확장을 기본적으로 지원하고 있다.
 
<br/>

### 핫스팟 문제
- 다른 서비스나 샤드보다 더 많은 데이터를 수신하는 서비스나 샤드를 핫스팟이라고 한다.
- 서버 과부하 문제가 발생할 수 있다.
- 더 많은 집계 서비스 노드를 할당하여 해결할 수 있다.

<br/>

### 결함 내성
- 스냅숏을 이용하면 집계 서비스의 복구 절차가 단순해진다.
- 어떤 집계 서비스 노드 하나에 장애가 발생하면 해당 노드를 새 것으로 대체한 다음 마지막 스냅숏에서 데이터를 복구하면 된다.
- 스냅숏을 마지막으로 찍은 후에 도착한 새로운 이벤트는, 새 집계 서비스 노드가 카프카 브로커에서 읽어가 다시 처리할 것이다.

<br/>

### 데이터 모니터링 및 정확성
- 지속적 모니터링
  - 지연 시간: 추적이 가능하도록 기록된 시각 사이의 차이를 시간 지표로 변환해서 모니터링하면 됨
  - 메시지 큐 크기: 카프카를 사용할 경우 레코드 처리 지연 지표를 대신 추적하면 됨
  - 집계 노드의 시스템 자원: CPU, 디스크, JVM 등 관련
 
<br/>

### 조정
- 다양한 데이터를 비교하여 데이터 무결성을 보증하는 기법을 말한다.
- 매일 각 파티션에 기록된 클릭 이벤트를 이벤트 발생 시각에 따라 정렬한 결과를 일괄 처리하여 만들어 낸 다음, 실시간 집계 결과와 비교해볼 수 있다.

<br/>

<img alt="image" width="500" src="https://github.com/user-attachments/assets/8b31b45a-5681-4474-8465-8228f6d40f53"/>

<br/>

### 대안적 설계안

<img alt="image" width="500" src="https://github.com/user-attachments/assets/706b6a79-abce-424d-a369-da257274ee6f"/>

<br/>

## 4️⃣ 마무리
- 데이터 모델 및 API 설계
- 맵리듀스 데이터 처리 패러다임을 통해 광고 클릭 이벤트를 집계하는 방안
- 메시지 큐, 집계 서비스, 데이터베이스의 규모 확장 방안
- 핫스팟 문제를 해결하는 방안
- 시스템의 지속적 모니터링
- 데이터 조정을 통한 정확성 보증 방안
- 결함 내성
