# 1장. 근접성 서비스

### 근접성 서비스(proximity service)란?

음식점, 호텔, 극장, 박물관 등 현재 위치에서 가까운 시설을 찾는 데 이용되는 기능

[EX]

- Yelp - 주변의 좋은 식당 검색
- Google Map - 가까운 k개 주유소 검색 기능

## 1단계 문제 이해 및 설계 범위 확정

### 요구사항 파악 by QnA

- 검색 반경(radius)
    - **주어진 반경 내의 사업장만 대상으로 지정**
    - 표시할 사업장이 충분하지 않은 경우는 따로 고려 X
    - 시스템이 자동적으로 범위 조정 X
    - 사용자가 직접 지정 불가능
- 최대 허용 반경
    - **20km (12.5 mile)**
- 사용자 기능
    - UI에서 검색 반경 선택 가능 [0.5km(0.31mile) | 1km(0.62mile) | 2km(1.24mile) | 5km(3.1mile) | 20km(12.42mile)]
    - 사업장에 대한 정보 추가/삭제/갱신 기능
        
        → 해당 작업 결과는 다음 날까지 반영되어야 함 (실시간 조회 X)
        
- 사용자 현위치에 따른 제약
    - 사용자의 이동 속도가 빠르지 않다고 가정
    - 상시적으로 페이지를 갱신할 필요 X
    - 이동한 위치에 따라 검색 결과는 달라져야 함

### 기능 요구사항

- 사용자의 위치(경도, 위도 쌍)와 검색 반경 정보에 배치되는 사업장 목록을 반환
- 사업장 소유주가 사업장 정보를 추가/삭제/갱신할 수 있도록 하되, 그 정보를 검색 결과에 실시간으로 반영될 필요가 없다고 가정
- 고객은 사업장의 상세 정보를 살필 수 있어야 함

### 비기능 요구사항

- 낮은 응답지연(latency) : 사용자는 주변 사업장을 신속히 검색할 수 있어야 함
- 데이터 보호(data privacy) : 위치 기반 서비스(LBS)에서 `사용자 위치`는 사생활에 관한 민감한 데이터이므로, CCPA와 같은 보호 법안을 준수해야 함
    
    *CCPA : California Consumer Privacy Act
    
- 고가용성(high availability) 및 규모 확장성(scalability) : 인구 밀집 지역에서 이용자가 집중되는 시간에 트래픽이 급증해도 감당 가능해야 함

### 개략적 규모 추정

> DAU 1억 명, 등록된 사업장 수는 2억이라고 가정하자.
> 
> - 한 사용자는 하루에 5회 검색을 시도한다고 가정

<aside>
🔎 QPS(Query per Second) 계산

$$
QPS = (1억ⅹ5) / 10^5 = 5000
$$

- 1일 = 24시간X60분X60초 = 86400초 = 10^5초
</aside>

## 2단계 개략적 설계안 제시 및 동의 구하기

### API 설계

- `GET` /v1/search/nearby
    
    > 특정 검색 기준에 맞는 사업장 목록 조회 API
    > 
    
    *페이지 단위로 나눠서 반환 (pagination)
    
    - Request Param
        
        
        | Name | Description | Type | Mandatory | Default |
        | --- | --- | --- | --- | --- |
        | latitude | 검색할 위도 | decimal | Required | X |
        | longitude | 검색할 경도 | decimal | Required | X |
        | radius | 검색 반경 | int | Optional | 5000m (약 3mile) |
- 사업장 관련 API
    
    
    | Name | Description | HTTP Method | API Endpoint |
    | --- | --- | --- | --- |
    | 사업장 조회 API | 특정 사업장의 상세 정보 반환 | GET | /v1/business/:id |
    | 사업장 등록 API | 새로운 사업장 추가 | POST | /v1/business |
    | 사업장 수정 API | 사업장 상세 정보 갱신 | PUT | /v1/business/:id |
    | 사업장 삭제 API | 특정 사업장 정보 삭제 | DELETE | /v1/business/:id |
    
    ex. Google Places API, Yelp business endpoint
    

### 데이터 모델

- 읽기/쓰기 비율
    
    > 읽기(read) >>> 쓰기(write)
    > 
    - Read
        - 주변 사업장 검색
        - 사업장 정보 확인(조회)
    - Write
        - 사업장 정보 추가/삭제/편집 ✅ 빈번하지 않음
    
- 데이터 스키마
    - business 테이블 : 사업장 상세 정보 저장
        
        ```sql
        business
        ----
        business_id  (pk)
        address
        city
        state
        country
        latitude
        longitude
        ```
        
    - 지리적 위치 색인 테이블(geospatial index table) : 위치 정보 관련 연산의 효율성을 높이는 데 사용

### 개략적 설계안

![Untitled](https://github.com/SPRING-STUDY-2023/System-Design-Interview/assets/80024278/3893b38e-e203-48b0-a601-835814d2bb5d)

- `로드밸런서`
    
    > 유입 트래픽을 자동으로 여러 서비스에 분산시키는 컴포넌트
    > 
    - 통상적으로 단일 DNS 진입점(entry point)을 지정하고, URL 경로를 분석하여 어느 서비스에 트래픽을 전달할지 결정함
- `LBS` (위치 기반 서비스, Located Base Service)  ⭐ 시스템의 핵심 부분
    
    > 주어진 위치와 반경 정보를 이용해 주변 사업장을 검색하는 역할
    > 
    - write(X), read만 빈번하게 발생하는 서비스
    - QPS가 높음 → 특정 시간대의 인구 밀집 지역일수록 그 경향이 심함
    - stateless 서비스 → 수평적 규모 확장이 쉬움
- `사업장 서비스`
    
    [요청의 종류]
    
    - 사업장 소유주가 사업장 정보를 생성/갱신/삭제할 때
        - 기본적으로 write
        - QPS는 높지 않음
    - 고객이 사업장 정보를 조회할 때
        - 특정 시간대에 QPS가 높아짐
- `데이터베이스 클러스터`
    
    > 주-부 데이터베이스 형태로 구성
    > 
    - 주(primary) : write 요청을 처리
    - 부(secondary) : read 요청을 처리
    
    데이터가 일단 `주` 데이터베이스 에 기록된 다음, `사본(부)` 데이터베이스에 복사되는 방식
    
    → 복제에 걸리는 시간 지연으로 주-부의 데이터 간 차이가 있을 수 있다. 
    
    하지만 이는 **실시간으로 갱신될 필요가 없기 때문에** 크게 문제되지는 않는다!
    
- `사업장 서비스와 LBS의 규모 확장성`
    
    점심시간과 같이 특정 시간대에 집중적으로 몰리는 트래픽에는 자동으로 서버를 추가하여 대응하고, 야간 등의 유휴 시간대에는 서버를 삭제하도록 구성할 수 있다
    
    +) 시스템을 클라우드에 둔다면, 여러 지역, 가용성 구역에 서버를 두어 시스템 가용성을 높일 수 있다!  ****상세 설계에서 추가 설명***
    

### 주변 사업장 검색 알고리즘

[Database example] GeoHash in Redis, PostGIS 익스텐션을 설치한 Postgres 

*위와 같은 DB의 내부 동작보다 **“지리적 위치 색인”**이 어떻게 동작하는 지 설명할 수 있는 것이 훨씬 중요하다

알고리즘의 ①사고 프로세스와 ②타협적 측면을 중심으로 살펴보자.

1. `2차원 검색` : 주어진 반경으로 그린 원 안에 놓인 사업장을 검색하는 방법
    
    *가장 직관적이지만 지나치게 단순함
    
    ```sql
    SELECT business_id, latitude, longitude
    FROM business
    WHERE (latitude BETWEEN {:my_lat} - radius AND {:my_lat} + radius)
     AND (longitude BETWEEN {:my_long} - radius AND {:my_long} + radius)
    ```
    
    - 이 질의는 테이블 전부를 읽는 방식이므로 비효율적
    - 위도와 경도 컬럼에 index를 걸어둔다면?
        - (위도, 경도) 데이터는 2차원이므로, 컬럼별로 가져온 결과도 매우 많다
        - 또한 각 컬럼에 대해 index를 걸어둔다면, 각각의 집합에 대한 추출을 빠르겠지만 두 집합의 교집합을 구하는 과정이 역시 오래 걸릴 것이다
        
        → 이를 개선하기 위한 방안으로 **2차원 데이터를 1차원에 대응**시켜보자!
        

<aside>
💡 **색인(index)을 만드는 방법**

![Untitled](https://github.com/SPRING-STUDY-2023/System-Design-Interview/assets/80024278/149931c3-9bfd-4bbe-818d-c1cd8fb8b948)

- 해시 기반 방안 : 균등 격자, 지오해시, 카르테시안 계층
- 트리 기반 방안 : 쿼드트리, 구글 S2, R-tree

### 개략적 IDEA

> 지도를 작은 영역으로 분할하고 고속 검색이 가능하도록 색인을 만드는 것
> 
</aside>

1. `균등 격자` : 지도를 작은 격자 or 구획으로 나누는 단순한 접근법
    - 하나의 격자는 여러 사업장을 담을 수 있고, 하나의 사업장은 한 격자 안에만 속하게 된다
    
    👎🏻 단점
    
    1. 사업장 분포가 균등하지 않음 (전 세계를 동일한 크기의 격자로 나누는 것이므로)
        
        *→ 인구 밀집 지역에는 작은 격자를, 그렇지 않은 지역에는 큰 격자를 사용한다면?*
        
    2. 주어진 격자의 인접 격자를 찾기 까다로울 수 있음
    
2. `지오해시` (Geohash) : 2차원의 위도 경도 데이터 → 1차원의 문자열로 변환
    
    > 비트를 하나씩 늘려가면서 재귀적으로 세계를 더 작은 격자로 분할해 나가는 알고리즘
    > 
    - `0` : 위도 범위 [-90, 0], 경도 범위 [-180, 0]에 대응
    - `1` : 위도 범위 [0, 90], 경도 범위 [0 180]에 대응
    
    **[개략적인 흐름]**
    
    1. 전 세계를 자오선과 적도 기준 사분면으로 나눈다.
        
        ![Untitled](https://github.com/SPRING-STUDY-2023/System-Design-Interview/assets/80024278/1d05d596-4e81-4a36-b05c-66ba77e43dc4)
        
    2. 각각의 격자를 또다시 사분면으로 나눈다. (각 격자는 경도와 위도 비트 순서를 반복하여 표현)
        
        ![Untitled](https://github.com/SPRING-STUDY-2023/System-Design-Interview/assets/80024278/a916dffe-c4cb-4626-b256-f5c3fd4b5fdb)
        
    3. 위 절차를 원하는 정밀도(precision)를 얻을 때까지 반복한다.
        
        *통상적으로 base32 표현법을 사용
        
        - 구글 본사 지오해시 (길이=6)
            
            1001 11010 01001 10001 11111 11110 (base32 이진 표기) → 9q9jhr (base32)
            
        - 메타(구 페이스북) 본사 지오해시 (길이=6)
            
            1001 11010 01001 10011 10001 11011 (base32 이진 표기) → 9q9jhr (base32)
            
    
    **[특징]**
    
    - 12단계 정밀도를 가짐 → 정밀도는 격자 크기를 결정하는 요소
    - 최적 정밀도 : 사용자가 지정한 반경으로 그린 원을 덮는 최소 크기 격자를 만드는 지오해시 길이
    - 격자 가장자리 처리 방식에 관한 경계 조건(edge case)
        
        > 해시값의 공통 접두어(prefix)가 긴 격자들이 서로 더 가깝게 놓이도록 보장한다
        > 
        > 
        > ![IMG_6294.HEIC](https://github.com/SPRING-STUDY-2023/System-Design-Interview/assets/80024278/da769414-7d0b-41af-b88c-e1e2685aaefc)
        > 
        - `**격자 가장자리 관련 이슈1` :** 아주 가까운 두 위치가 어떤 공통 접두어도 갖지 않을 수 있다.
            - 지구는 둥글기 때문!
            - ex. 두 지점이 적도의 다른 쪽에 놓이거나, 자오선상의 다른 반쪽에 놓이는 경우 → 단순한 접두어 기반 SQL로는 모든 사업장을 가져올 수 없음
        - `**격자 가장자리 관련 이슈2` :** 두 지점이 공통 접두어 길이는 길지만 서로 다른 격자에 놓이는 경우
            - 해결책 - 현재 격자를 비롯한 인접한 모든 격자의 모든 사업장 정보 가져오기
                
                *특정 지오해시의 주변 지오해시를 찾는 것은 상수시간에 가능한 연산!
                
        - `**표시할 사업장이 충분하지 않은 경우`**
            
            (i) 주어진 반경 내 사업장만 반환하거나 
            (ii) 검색 반경을 키우기(지오해시 값의 마지막 비트를 삭제하여 얻은 지오해시 값을 사용해 주변 사업장을 검색하는 것)
            
        
3. `쿼드트리` (quadtree) : 격자의 내용이 특정 기준을 만족할 때까지 2차원 공간을 재귀적으로 사분면 분할하는 데 흔히 사용되는 자료구조
    
    ![사업적 필요에 따라 격자에 담긴 사업장 수를 분할하는 방식](https://github.com/SPRING-STUDY-2023/System-Design-Interview/assets/80024278/9cc757da-d9a1-435c-9982-efced73f88a7)
    
    사업적 필요에 따라 격자에 담긴 사업장 수를 분할하는 방식
    
    - 질의에 답하는 데 사용될 트리 구조를 메모리 안에 만드는 것
        
        ❗ 메모리 안에 놓이는 자료구조 (O), 데이터베이스 (X)
        
    - 이는 각각의 LBS 서버에 존재해야 함
    - 서버 시작 시점에 구축됨
    
    [ex] 전 세계에 200 million개의 사업장이 있다고 가정하자.
    
    ![위 그림을 트리로 시각화 해보자!](https://github.com/SPRING-STUDY-2023/System-Design-Interview/assets/80024278/a5e60b36-2f8f-4770-ab8a-44a42079ab04)
    
    위 그림을 트리로 시각화 해보자!
    
    - 루트 노드 = 세계 전체 지도
    - 루트 노드를 사분면 각각을 나타내는 하위노드로, 어떤 노드의 사업장도 100개를 넘지 않을 때까지 재귀적으로 분할한다
    - 의사코드
        
        ```java
        public void buildQuadtree(TreeNode node) {
        		if (countNumberOfBusinessInCurrentGrid(node) > 100) {
        				node.subdivide();
        				for (TreeNode child : node.getChildren()) {
        						buildQuadtree(child);
        				}
        		}
        }
        ```
        
    
    <aside>
    🧐 쿼드 트리 전부를 저장하는 데 얼마나 많은 메모리가 필요한가?
    
    - 말단 노드에 수록되는 데이터
        
        
        | 이름 | 크기 |
        | --- | --- |
        | 격자를 식별하는 데 사용될 좌상단과 우하단 꼭짓점 좌표 | 32 byte (8byte X 4) |
        | 격자 내부 사업장 ID 목록 | ID당 8byte X 100 (한 격자에 허용되는 사업장 수의 최댓값) |
        | 합계 | 832 byte |
    - 내부 노드에 수록되는 데이터
        
        
        | 이름 | 크기 |
        | --- | --- |
        | 격자를 식별하는 데 사용될 좌상단과 우하단 꼭짓점 좌표 | 32 byte (8byte X 4) |
        | 하위 노드 4개를 가리킬 포인터 | 32 byte (8byte X 4) |
        | 합계 | 64 byte |
    
    ❗ 한 격자에 허용되는 사업장 수의 최댓값을 트리 안에 저장하지 않아도 된다 (이미 DB 레코드는 최댓값을 고려하여 분할되어 있기 때문)
    
    **[메모리 사용량]**
    
    - 격자 안에는 최대 100개의 사업장이 있을 수 있다
    - 말단 노드의 수 = 200million/100 = 약 2million
    - 내부 노드의 수 = 말단 노드의 수 X 1/3 = 2milliion X 1/3 = 약 0.67million
    - 총 메모리 요구량 = 2million X 832byte + 0.67million X 64byte = **약 1.71GB**
    
    ⇒ 트리를 구축하는 데 드는 부가적인 메모리 요구량을 감안하더라도, 총 메모리 요구량이 꽤 작은 편이다!
    
    **즉, 쿼드트리 인덱스가 메모리를 많이 잡아먹지 않으므로 서버 1대에 충분히 올릴 수 있다는 것만 확실히 알아두자. 만약, 서버 1대로 감당이 어렵다면 read 연산을 여러 대 쿼드트리 서버로 분산시켜야 할 것이다.** 
    
    </aside>
    
    <aside>
    🧐 전체 쿼드트리 구축에 소요되는 시간은?
    
    - 각 말단 노드에는 약 100개 사업장 ID가 저장된다
    - 전체 사업장 수는 n개라고 하자.
    
    > 시간 복잡도 = n/100 log(n/100)
    > 
    
    → 200 million 개의 사업장 정보를 인덱싱하는 쿼드트리 구축에는 몇 분 정도 소요될 것!
    
    </aside>
    
    <aside>
    🧐 쿼드트리로 주변 사업장을 검색하려면?
    
    1. 메모리에 쿼드트리 인덱스를 구축한다
    2. 검색 시작점이 포함된 말단 노드를 만날 때까지, 트리의 루트 노드부터 탐색한다
        - 해당 노드에 100개 사업장이 있는 경우, 해당 노드만 반환
        - 그렇지 않은 경우, 충분한 사업장 수가 확보될 때까지 인접 노드 추가
    </aside>
    
    - 쿼드트리 운영 시 고려사항
        - 새로운 버전의 서버 SW를 릴리즈 할 때, 동시에 너무 많은 서버에 배포하지 않도록 조심할 것
            
            서버를 시작하는 순간에 트리를 구축하기 시작하면 오랜 시간이 걸리며 서버가 트래픽을 일시적으로 처리하지 못할 것이다. 
            
        - 적절한 배포 방안 채택
            
            ex. blue/green 배포 - 프로덕션 환경의 절반가량을 항상 실제 서비스가 아닌 신규 이미지 테스트에 사용 & 테스트에 통과한 경우 네트워크 설정을 조정하여 테스트 환경과 실제 서비스 환경을 맞바꾸는 배포 전략이 모든 서버에 동시 배포하는 상황에서 큰 부하를 가할 수 있다.
            
            *설계가 더욱 복잡해짐을 강조
            
        - 사업장 추가/삭제 시의 쿼드트리 갱신
            1. 점진적으로 갱신하기 (가장 쉬움)
                
                클러스터 낸의 모든 서버를 한번에 (x) 점진적으로 몇 개씩만 (o) 갱신하는 것
                
                👎🏻 짧은 시간동안 낡은 데이터를 반환할 수도 있음
                
            2. 미리 합의 후, 캐시를 일괄적으로 갱신하기
                
                👎🏻 수많은 key가 한번에 무효화되어 캐시 서버에 막대한 부하가 가해질 수도 있음
                
            3. 쿼드트리 실시간 갱신하기
                
                여러 스레드가 쿼드트리 자료구조를 동시 접근하는 경우 (락 메커니즘 사용) 등 설계가 복잡해짐
                
            
    - 실제 쿼드트리 활용 사례
        
        Yext가 제공한 Denver 인근 쿼드트리 구축 사례 - 인구 밀집 지역에는 작은 격자, 그렇지 않은 지역은 큰 격자를 사용한다. 
        
    
4. `구글 S2` (Google S2 geometry library) : 지구를 힐베르트 곡선이라는 공간 채움 곡선을 사용하여 1차원 색인화(indexing)하는 방안
    - 메모리 기반(in-memory)
    - 힐베르트 곡선의 특징
        
        > 힐베르트 곡선 상에서 인접한 두 지점은 indexing 이후 1차원 공간 내에서도 인접한 위치에 있다 (1차원 공간 내에서의 검색이 2차원보다 훨씬 효율적)
        > 
        > 
        > ![Untitled](https://github.com/SPRING-STUDY-2023/System-Design-Interview/assets/80024278/1ff605b9-a6d6-4706-b997-0856736cf2b3)
        > 
    
    - 활용 사례
        
        구글, 틴더(Tinder) 등의 회사에서 널리 쓰임
        
    
    <aside>
    💡 지오펜스(Geofence)
    
    임의 지역에 다양한 수준의 영역 지정이 가능하도록 하는 **“실세계 지리적 영역에 설정한 가상의 경계(perimeter)”**
    
    - 동적 지정 (e.g 특정 지점 반경 몇 km 이내)
    - 이미 존재하는 경계들을 묶어서 지정 (e.g 스쿨 존, 동네 경계)
    </aside>
    
    <aside>
    💡 영역 지정 알고리즘(Region Cover Algorithm)
    
    지오해시처럼 고정된 정밀도를 사용하는 대신 최소 수준, 최고 수준, 최대 셀 개수 등을 지정할 수 있다
    
    - 셀 크기를 유연하게 조정할 수 있어 보다 상세함
    </aside>
    

### 추천 솔루션

| 인덱싱 방법 | 회사 |
| --- | --- |
| 지오해시 | Bing 지도, Redis, MongoDB, Lyft |
| 쿼드트리 | 엑스트(Yext) |
| 지오해시+쿼드트리 | Elasticsearch |
| S2 | Google Maps, 틴더(Tinder) |

### 지오해시 VS 쿼드트리

지오해시

👍🏻 장점

- 구현과 사용이 쉬움 (트리를 구축할 필요 X)
- 지정 반경 이내 사업장 검색 지원
- 정밀도를 고정하면 격자 크기도 고정됨
- index 갱신이 쉬움
    
    ex. index에서 사업장을 하나 삭제하려면? (geohash, business_id)와 같은 열 하나만 제거하면 된다
    

👎🏻 단점

- 인구밀도에 따라 동적으로 격자 크기 조정 X

쿼드트리

👍🏻 장점

- k번째로 가까운 사업장까지의 목록을 구할 수 있음 (하위 노드 분할 과정이 k개에 기반하며, k개 사업장을 찾을 때까지 검색 범위를 자동으로 조정할 수 있기 때문)
- 인구 밀도에 따라 격자 크기를 동적으로 조정 가능

👎🏻 단점

- 구현이 까다로움 (트리 구축 필요)
- index 갱신이 까다로움 (루트노드~말단노드까지 전부 탐색해야 하므로)
    
    쿼드트리 = 자료구조
    
    → 시간 복잡도 = O(logn)
    
- 다중 스레드를 지원해야 하는 경우 더욱 복잡해짐 (lock을 사용해야 하기 때문)

## 3단계 상세 설계

### 데이터베이스의 규모 확장성

- 사업장 테이블 (business)
    
    사업장 데이터는 한 서버에 담을 수 없을 수도 있기에, `**샤딩`(사업장 ID 기준)**을 적용하기 좋다!
    
    → 모든 샤드에 부하를 고르게 분산할 수 있을 분 아니라, 운영적 측면에서도 관리하기 쉬움
    
- 지리 정보 색인 테이블
    
    지오해시, 쿼드트리 중 **지오해시**를 사용 
    
    **[지오해시 테이블 구성 방법]**
    
    1. 각각의 지오해시에 연결되는 모든 사업장 ID를 JSON 배열로 만들어 같은 열에 저장하는 방안
        
        → 특정한 지오해시에 속한 모든 사업장 ID가 하나의 열에 보관됨
        
        ```java
        geospatial_index
        ---
        geohash
        list_of_business_ids
        ```
        
        - JSON 배열을 읽은 다음 갱신할 사업장 ID를 찾아야 함
        - 새 사업장을 등록하는 경우, 중복 체크를 위해 데이터를 전부 살펴봐야 함
        - 병렬적으로 실행되는 갱신 연산 결과로 데이터가 소실되지 않도록 락을 사용해야 함
        
        ⇒ 따져야 할 경계 조건 多
        
    2. 같은 지오해시에 속한 사업장 ID 각각을 별도 열로 저장하는 방안 ⭐ **추천**
        
        → 사업장마다 1개의 레코드가 필요함
        
        ```java
        geospatial_index
        ---
        geohash
        business_id
        ```
        
        - 복합 키 (geohash, business_id)를 사용 ⇒ 추가, 삭제가 쉬움
        - 락을 사용할 필요 X
        

<aside>
🗺️ 지리 정보 index의 규모 확장

***테이블에 보관되는 데이터의 실제 크기를 고려하지 않고 샤딩 방법을 결정하는 건 섣부르다.***

지리 정보 색인 테이블 구축에 필요한 전체 데이터 양은 많지 않으므로(약 1.71GB) 실질적으로 index 전부를 최신 DB 서버 한 대에 충분히 수용 가능하다

> ⚠️ read가 빈번하다면? 여러 DB 서버로 부하를 분산해야 한다
> 
> 
> **[분산 전략]**
> 
> 1. 읽기 연산을 지원할 사본 데이터베이스 서버를 늘리는 것
> 2. 샤딩을 적용하는 것
</aside>

### 캐시(cache)

- 처리 부하가 read 중심이고 데이터베이스 크기는 상대적으로 작아서 모든 데이터는 한 대의 데이터베이스 서버에 수용 가능하다
    - 질의문 처리 성능 - I/O에 좌우되지 않으므로, 메모리 캐시를 사용할 때와 비슷함
- 읽기 성능이 병목인 경우, 사본 데이터베이스를 증설해서 읽기 대역폭을 늘릴 수 있다

1. `캐시 키`
    
    > 사용자 위치의 위도, 경도 정보 (가장 직관적)
    > 
    
    [문제점] 추정치에 불과, 사용자가 이동할 때마다 미세하게 변경됨
    
    ⇒ 위치에 따라 종속적으로 변하는 데이터는 캐시 키로 적절하지 않다!
    
    > ⭐ 지오해시나 쿼드트리로 **같은 격자 내 모든 사업장이 같은 해시 값을 갖도록** 만들자
    > 
    
2. `캐시 데이터 유형`
    
    
    | 키 | 값 |
    | --- | --- |
    | 지오해시 | 해당 격자 내의 사업장 ID 목록 |
    | 사업장 ID | 사업장 정보 객체 |
    - **격자 내 사업장 ID**
        
        > 특정 지오해시에 대응되는 사업장 ID 목록을 미리 계산한 다음, Redis와 같은 키-값 저장소에 캐시하자!
        > 
        
        사업장 정보 - 자주 변경 X, 상대적으로 안정적
        
        1. 주어진 지오해시의 사업장 ID 목록 구하기
            
            ```sql
            SELECT business_id FROM geohash_index
            WHERE geohash LIKE '{: geohash}%'
            ```
            
        2. 요청을 받으면 먼저 캐시 조회 → 캐시에 없다면 위 질의로 목록을 가져와 캐시에 보관
            
            ```java
            public List<String> getNearbyBusinessIds(String geohash) {
            		String cacheKey = hash(geohash);
            		List<String> listOfBusinessIds = Redis.get(cacheKey);
            		if (listOfBusinessIds == null) {
            				listOfBusinessIds = 위 SQL 실행 결과;
            				Cache.set(cacheKey, listOfBusinessIds, "id");
            		}
            		return listOfBusinessIds;
            }
            ```
            
        - 추가/수정/삭제 - DB 갱신 후, 캐시에 보관된 항목은 무효화(invalidate)
            - 해당 연산의 빈도는 상대적으로 낮아, 락을 사용할 필요X
            - 사업장 정보 갱신의 구현 난이도는 Easy
        - 사용자는 [500m(4) / 1km(5) / 2km(5) / 5km(6)] 의 검색 반경 중 하나를 고를 수 있다
            - ( ) 안의 4,5,6은 정밀도를 의미
            - 각각에 대한 주변 사업장 검색 결과를 신속하게 제공하려면, 3가지 정밀도 전부에 대한 검색 결과를 Redis에 캐시해야 한다
        
        <aside>
        📊 필요한 메모리 요구량
        
        - Redis 저장소에 값(value)을 저장하기 위한 필요 공간 : 8byte X 2million X 3가지 정밀도 =~ 5GB
        - Redis 저장소에 키(key)를 저장하기 위한 필요 공간 : 무시할 만한 수준
        
        ⇒ 전체 메모리 요구량 : 대략 5GB
        
        </aside>
        
        고가용성을 보장하고 대륙 경계를 넘는 트래픽의 전송지연을 방지하기 위해서, Redis 클러스터를 전 세계에 각 지역벼로 두고, 동일한 데이터를 각 지역에 중복해서 저장해두어야 한다
        
        → 이러한 종류의 Redis Cache를 최종 설계 도면에서는 `지오해시`라고 지칭한다
        
    - **클라이언트 애플리케이션에 표시할 사업장 정보**
        
        *쉽게 캐시가 가능한 형태
        
        > 키 : business_id - 값 : 사업장 이름, 주소, 사진 등의 정보를 담은 객체
        > 
        
        → 최종 설계 도면에서는 `사업장 정보`라고 지칭한다
        

### 지역(region) 및 가용성 구역(availability zone)

여러 지역과 가용성 구역에 설치하는 것의 기대 효과

1. 사용자와 시스템 사이의 물리적 거리를 최소화 (자신의 인근 지역 데이터센터로 연결)
    
    👤 미국 서부 사용자 → 미국 서부 데이터센터, 유럽 사용자 → 유럽 데이터센터
    
2. 트래픽을 인구에 따라 고르게 분산하는 유연성 확보
    
    인구 밀도가 높은 지역은 별도로 빼거나 한 지역 내에서도 여러 가용성 구역을 활용해 부하를 분산시킬 수 있다
    
3. 해당 지역의 사생활 보호법에 맞는 운영 가능
    
    🚫 특정 국가는 사용자 데이터를 해당 국가 외 지역으로 전송이 불가능함
    
    → 해당 국가는 별도 지역으로 빼고, 이 지역에서 발생하는 모든 트래픽을 DNS 라우팅을 통해 해당 지역 내 서비스에서 처리하도록 우회하는 방식
    

### 시간대 또는 사업장 유형에 따른 검색 (➕)

*Q. 현재 영업 중인 사업장 정보만 받아오려면?*

A. 지오해시나 쿼드트리와 같은 메커니즘으로는 상대적으로 결과 사업장 수가 적으므로, 일단 근처 사업장 ID를 확보한 후 해당 사업장 정보를 전부 추출하여 영업시간이나 사업장 유형에 따라 필터링 하는 방식을 고려해볼 수 있다.  (사업장 정보 테이블에 데이터가 존재한다는 전제 하)

### 최종 아키텍처 다이어그램

![IMG_6311.jpg](https://github.com/SPRING-STUDY-2023/System-Design-Interview2/assets/80024278/84182b45-edfc-47fd-a12d-2b2ec6e281a9)

**[주변 사업장 검색] “옐프에서 주변 반경 500m 내 모든 식당을 찾는 경우”**

1. 클라이언트 앱은 사용자의 위치(위도, 경도 정보)와 검색 반경(500m)을 로드밸런서로 전송한다
2. 로드밸런서는 해당 요청을 LBS로 보낸다
3. 주어진 사용자 위치와 반경 정보에 의거하여, LBS는 검색 요건을 만족할 지오해시 길이를 계산한다 (정밀도는 6)
4. LBS는 인접한 지오해시를 계산한 다음, 목록에 추가한다
    
    ```java
    list_of_geohashes = [my_geohash, neighbor1_geohash, neighbor2_geohash, ..., neighbor8_geohash]
    ```
    
5. `list_of_geohashes` 내에 있는 지오해시 각각에 대해 LBS는 ‘지오해시’ Redis 서버를 호출하여 해당 지오해시에 대응하는 모든 사업장 ID를 추출한다 
    - 지오해시별로 사업장 ID 목록을 가져오는 연산을 병렬적으로 수행하면, 검색 결과를 내는 지연시간을 줄일 수 있다
6. 반환된 사업장 ID를 가지고 ‘사업장 정보’ Redis 서버를 조회하여 각 사업장의 상세 정보를 취득한다
    - 해당 상세 정보에 의거하여 사업장과 사용자 간 거리를 확실하게 계산하고, 우선순위를 매긴 다음 클라이언트 앱에 반환한다

**[사업장 정보 CRUD]**

모든 사업장 관련 API는 LBS와는 분리되어 있다

1. 사업장 정보 서비스는 요청 데이터가 ‘사업장 정보’ Redis 서버에 기록되어 있는지 확인한다
    1. 캐시되어 있다면? 해당 데이터를 읽어 클라이언트로 반환한다
    2. 캐시에 없다면? 데이터베이스 클러스터에서 사업장 정보를 읽어 캐시에 저장한 후 반환한다 (뒤이은 요청을 캐시로 처리하도록)
2. 캐시에 보관된 정보 갱신은 밤 사이에 작업을 돌려서 처리한다 (미리 사업장과 갱신 조건에 대해 합의된 경우)

## 4단계 마무리

![Untitled](https://github.com/SPRING-STUDY-2023/System-Design-Interview2/assets/80024278/0ba88142-e395-45bc-a870-bb4abeb43f80)
